# 0x08. Deep Convolutional Architectures

## Resources:books:
Read or watch:

* Vanishing Gradient Problem
* 1x1 Convolutions
* What does 1x1 convolution mean in a neural network?
* GoogLeNet Tutorial
* Review: GoogLeNet (Inception v1)— Winner of ILSVRC 2014 (Image Classification)
* Residual Neural Network
* An Overview of ResNet and its Variants
* Review: ResNet — Winner of ILSVRC 2015 (Image Classification, Localization, Detection)
* Deep Residual Learning for Image Recognition
* Review: ResNeXt — 1st Runner Up in ILSVRC 2016 (Image Classification)
* Review: DenseNet — Dense Convolutional Network (Image Classification)
* Densely Connected Convolutional Networks
* Network In Network (Note: I suggest watching this video at 1.5x - 2x speed)
* Inception Network Motivation (Note: I suggest watching this video at 1.5x - 2x speed)
* Inception Network (Note: I suggest watching this video at 1.5x - 2x speed)
* Resnets (Note: I suggest watching this video at 1.5x - 2x speed)
* Why ResNets Work (Note: I suggest watching this video at 1.5x - 2x speed)
* Network in Network (2014)
* Going Deeper with Convolutions (2014)
* Highway Networks (2015)
* Deep Residual Learning for Image Recognition (2015)
* Aggregated Residual Transformations for Deep Neural Networks (2017)
* Densely Connected Convolutional Networks (2018)
* Multi-Scale Dense Networks for Resource Efficient Image Classification (2018)

---
## Learning Objectives:bulb:
What you should learn from this project:

* What is a skip connection?
* What is a bottleneck layer?
* What is the Inception Network?
* What is ResNet? ResNeXt? DenseNet?
* How to replicate a network architecture by reading a journal article
---
---

## Author
* **Gabriel Cifuentes** - [gcifuentess](https://github.com/gcifuentess)